I"{<p>HiSilicon: 화웨이의 칩 설계 회사<br />
<br />
메모리 회사: 어느 정도 용량의 메모리가 가장 수요가 많을지, 어느 정도 전력 소비까지 고객이 감내할 수 있는지 확인<br />
<br />
인텔같은 로직 회사: 고객이 어느 정도의 CPU 성능을 요구할지, 노트북 고객들은 어느 정도의 배터리 수명을 요구하고 CPU로부터 어느 정도의 전력 및 발열까지 감내할 수 있는지를 조사한다.<br />
<br />
D램은 사용자로부터 명령과 주소를 받는 부분, 주소를 해독하는 부분, 데이터 저장소, 읽어온 데이터를 잠시 보관해두는 latch로 비교적 간단하게 구성된다.<br />
<br />
D램은 설계 기술이 상대적으로 적게 필요하고, 대신 면적의 대부분을 차지하는 데이터 저장소의 면적을 줄이는게 중요하다.<br />
<br />
현대 CPU들은 다층의 캐시메모리, 디코더, ROB, 대기소, 연산포트, ALU등 다양한 기능을 하는 많고 작은 하드웨어들로 연결되어 있다.<br />
<br />
chip의 설계를 도와주는 EDA, 설계를 제조기술에 맞춰주는 PDK<br />
<br />
하드웨어 버그 예시로는 인텔 CPU의 보안 결함?<br />
<br />
테스트 후에는 원래 패키징해서 팔지만, 공간이 중요해지며 아예 웨이퍼 단위로 사고팔기도 한다.<br />
<br />
요즘은 여러개 CPU나 CPU+GPU 등의 구조로 Heterogeneous 칩을 고속 인터커넥트로 연결해 한 패키지로 팔기도 한다.<br />
<br />
Dhrystone: 1984년에 제안된 컴퓨터 성능 측정의 지표<br />
<br />
인텔 11900K는 1초에 4,110억개 명령어를 처리한다(Dhrystone 기준)<br />
<br />
컴퓨터: CPU, 메모리, 보조기억장치(HDD, SSD, USB메모리 등)<br />
<br />
반도체 제조업이 다른 제조업드로가 구분되는 가장 큰 차이점은 기술력이 미치는 영향이 막대하다는 점이다.<br />
<br />
1980년 1MB 메모리 가격: 6480달러<br />
2015년 1MB 메모리 가격: 0.0042달러 (백만배정도 싸졌다)<br />
다른 제조업들은 이정도로 못줄인다<br />
<br />
Dennard Scaling: 같은 면적에 집적된 트랜지스터는 전력 소모량이 같다.<br />
그래서 기술이 앞서는 회사는 전력소모 특성도 앞서나간다. 같은 면적 안에 트랜지스터가 100개든 100만개든 전력 소모는 같으니까.<br />
<br />
그리고 반도체는 다른 제조업에 비해 부피가 작고 부가가치가 높은 편이라서, 한 회사가 만들어 전 세계로 수출할 수 있다.<br />
그래서 빵집마냥 다른 동네로 도망가서 장사하는게 안된다. 전세계랑 경쟁해야된다.<br />
<br />
제조원가에서 설비 투자 비용이 차지하는 비중이 압도적으로 크다는 점도 다른 제조업들과 다르다.<br />
<br />
그래서 매년 엄청난 돈을 장비에 써야 한다. 즉, 고정비용이 크다.<br />
고정비용이 크다는건, 그 해 생산을 안하더라도 아낄 수 있는 비용이 얼마 안된다는 뜻이다.<br />
<br />
게다가, 반도체 공장은 공장 재가동에 시간이 오래 걸린다.<br />
<br />
일반적으로 반도체는 포토마스크 한장을 처리하는 데에 하루 이상이 걸리며,<br />
구조가 간단하다는 DRAM도 2000년에 이미 20장 넘는 마스크를 사용했다.<br />
<br />
2013년에는 DRAM 웨이퍼 한장이 필요로 하는 마스크 수가 40장을 넘었다. 그만큼 오래 걸린다.<br />
<br />
결국, 제품 가격이 떡락했다고 해도, 생산을 멈추면 손해다. 변동비용이 매출액보다 커지면 그때는 생산을 멈춰야 하겠지만, 반도체 생산에서 변동비용은 상당히 작다. 고정비용이 그만큼 커서 그렇다.<br />
<br />
여기서 말하는 변동비용은 인건비, 웨이퍼 가격, 재료 가격<br />
<br />
그럼 제품 가격이 떡락하면 회사를 팔아버리는건? 회사마다 공장에서 쓰는 장비가 많이 달라서 어렵다.<br />
삼성전자는 지금까지 단 한번도 메모리 회사를 인수한 적이 없다.<br />
<br />
그래서, 물량으로 시장 점유율을 가져왔더라도, 가격이 떡락하면 떡락을 막을 수가 없다.<br />
어떻게어떻게 버텨서 살아남으면? 바닥회사들이 죽어서 싸움이 끝난건데, 이 경우 1등 기업과 겨우 살아남은 회사의 사정은 크게 차이난다. 기술력에 의한 원가 절감 차이가 엄청나니까. 그래서 1등을 절대 못따라잡는다.<br />
<br />
그래서 메모리 반도체 시장에서는, 설비투자를 해버렸으면 연구개발과 재무운영 외에는 해볼 수 있는게 없다.<br />
<br />
인텔 4004: 최초의 마이크로프로세서. ALU, 레지스터 등을 모두 웨이퍼조각 하나 위에 올려놨다.<br />
4bit연산까지밖에 안됐지만, 이거 이후로 컴퓨터 가격이 떨어지기 시작했다.<br />
<br />
1975: IBM 5100(1.9MHz CPU, 64kB 메모리)<br />
1987: IBM XT(4.77MHz CPU, 640kB 메모리)<br />
<br />
1983년 삼성전자의 도쿄 선언: 메모리 사업 시작하겠다<br />
<br />
일본 메모리는 품질 위주, 삼성전자는 원가 위주 -&gt; 딱 시장에 필요한 성능만 내고 나머지는 원가절감 하겠다.<br />
일본 메모리는 품질을 위해 제조공정이 길고, 장비 종류도 많았다.<br />
<br />
1989년, DRAM 용량이 4MBit를 넘어가자 DRAM의 형태가 문제되기 시작했다.<br />
<br />
지금까지는 평면에 트랜지스터와 DRAM을 함께 늘어놓는 식이었는데, 밀도를 높이려면 다른 방식을 써야 했다.<br />
<br />
Trench형과 Stack형을 두고 논쟁이 많았는데, 진대제, 권오현이 Stack이 낫다고 해서 이건희가 Stack으로 가자고 했다.<br />
<br />
이때 IBM, 도시바, NEC 등이 다 트렌치 하는동안 삼성전자만 Stack을 했고, 옳은 결정이었기에 4MBit Dram이 대박을 친다.<br />
*Stack방식의 장점 적어놓기. 불량분석 이득이었던듯?<br />
<br />
반도체 산업이 처음 시작됐을때는 100mm 웨이퍼를 썼다. 1980년대 들어서는 150mm, 90년대 들어서는 200mm가 주류가 됐다.<br />
웨이퍼가 커질수록 버려지는 부분도 줄어드니까, 면적비 이상의 이득이 난다.<br />
100mm 웨이퍼와 300mm웨이퍼는 웨이퍼당 칩 갯수가 10배 넘게 차이난다.<br />
<br />
유명한 빅 칩중 하나인 IBM의 POWER9는 25x27mm다.<br />
<br />
2001년, 웨이퍼 업체들이 300mm 양산기술을 확보했다. 메모리업체들 입장에서는 당연히 바꾸는게 장기적으로 이득이지만, 불황 시기에 엄청 비싼 장비들을 사와야 한다는게 부담으로 다가왔다. 공정 최적화도 또 해야 하는데.<br />
<br />
이 불황은 2000년 10월의 닷컴버블 붕괴 때문이다. 버블 고점에서는 64MBit DRAM이 20달러였는데, 2001년 2월에에는 3.8달러가 됐다.<br />
하여간, 회사들은 돈이 없어 300mm를 바로 도입 못했다. 안그래도 불황인데 여기서 또 문제생기면 그땐 진짜 망할 수도 있으니까.<br />
<br />
근데 삼성전자는 빠꾸 안치고 2001년 10월에 300mm 웨이퍼 공정을 도입했다. 그래서 2001년에는 메모리 업체들 중 삼성전자만 흑자였다는데, 10월에 도입했는데??<br />
<br />
DRAM Cell은 원래 8F^2 구조였다가 6F^2 구조로 개선됐다. 6F^2구조가 밀도가 더 높다.<br />
마이크론이 2006년 처음 했고, 바로 삼성전자도 시작했다.<br />
<br />
일본 기업들은 1등을 뺏겼지만, 삼성전자는 6F^2 cell, 300mm공장등을 해내며 계속 1등을 이어갔다.<br />
<br />
결국 원가를 깎아서 삼성전자가 이긴거다. 비싸고 오래가는 메모리는 필요 없는 시대가 됐다.<br />
삼성전자가 기술이 훌륭했다기보다는 시대 흐름을 잘 탄거다.<br />
<br />
컴퓨터의 구성 요소: CPU, 메모리, 보조기억장치(HDD, SSD)<br />
보조기억장치는 초기 컴퓨터 이론에 존재하지 않았다. 폰 노이만 구조에는 메모리, CPU만 존재한다.<br />
(그림)<br />
뭐 전원 꺼지면 메모리가 날아간다 라고 폰 노이만 구조에 적혀 있지는 않은데,<br />
실제로는 DRAM, SRAM으로 메모리를 만들게 되어 전원이 꺼지면 메모리가 날아가게 되었다. 이건 좀 문제가 됐다.<br />
<br />
전원이 꺼져도 데이터를 보존하는 기억장치가 필요해졌다.<br />
<br />
이때, CPU가 메모리 이외 공간에 데이터를 보낸다는건 그 데이터는 당분간 필요 없다는 뜻일거다.<br />
따라서, 데이터 보존 장치의 성능은 좀 떨어져도 될 것이다.<br />
<br />
DRAM은 CPU가 직접 접근해야 하기 때문에, 메모리의 모든 방이 CPU에서 바로 접근 가능해야 했다.<br />
이는 메모리 설계에서 큰 부담으로 작용했다.<br />
모든 데이터 방에 금속을 설치해서 연결해야 하기 때문이다.<br />
<br />
결국 큰 단위로 데이터를 저장하고, 데이터가 필요할 때는 그 단위를 통째로 불러와 필요한 것만 찾아 쓰는 방식이 되었다. 이게 더 원가가 낮았다.<br />
<br />
처음에는 메모리로 자기 테이프를 썼는데, 원하는 데이터가 테이프 시작과 끝에 흩어져 있으면 테이프를 여러번 감았다 풀었다 하며 읽어야 했다.<br />
이 경우 성능이 안좋았다.<br />
<br />
1956년, IBM이 하드디스크를 내놓는다.<br />
하드디스크는 구조상 최고성능-최악성능 차이가 적다. 테이프는 엄청 크다. 그림으로 설명 가능<br />
즉, 카세트테이프는 순차접근만 가능, 하드디스크는 무작위 접근이 가능하다.<br />
<br />
HDD는 자기 테이프보다 비쌌지만, 성능도 좋고 관리도 쉬웠다.<br />
세계 HDD 출하량: 1996년 1억대, 2013년 8억대<br />
<br />
근데, CPU 성능은 2001년(펜티엄 1.2GHz) ~ 2012년(샌디브리지 3.3GHz)동안 24배 증가(코어성능 6배, 코어개수 4배)했고,<br />
메모리 가격 대비 용량은 128배, 전송속도는 12배, 접근속도는 4배(2001년 PC-133, 2012년 DDR3-1600) 증가했다.<br />
<br />
CPU와 메모리의 발전은 이렇게 빨랐는데, HDD의 발전은 느렸다.<br />
웨스턴디지털의 HDD 성능, 용량 변화:<br />
2001(WB100EB): 전송속도 40, 반응속도 12.1, 용량 10GB<br />
2012(WD10EZEX): 전송속도 150, 반응속도 8.9, 용량 1TB *단위 확인 필요<br />
<br />
하드디스크를 보면 용량은 100배 늘었지만 최대 전송속도가 3.75배밖에 안올랐고,<br />
반응속도는 그냥 모터를 5400RPM에서 7200RPM으로 높인게 다다.<br />
<br />
그리고, 데이터 안정성 때문에 3.5인치 이상 디스크에서는 회전속도를 7200RPM 이상으로 올리는게 힘들었다.<br />
<br />
게다가 컴퓨팅 기술이 발전해서 각종 프로그램, OS가 발전해 파일들의 크기가 커졌고,<br />
그러면 사용자가 프로그램을 실행하면 하드디스크 여러곳을 탐색하며 다음 파일을 읽어야 하는데, 여기에서 큰 성능 하락이 발생했다.<br />
<br />
1995년에는 MS-DOS를 썼고, 2010년에는 윈도우7을 썼다.<br />
1995년에는 MS-DOS를 용량 1.44MB짜리 3.5인치 플로피디스크에 담아 썼는데(MS-DOS의 용량이 몇인지는 모르겠다)<br />
2010년 윈도우7은 용량이 2GB가 넘는다.<br />
<br />
DOS때는 부팅시 3~10개 파일만 로드하면 됐었는데, 윈도우 부팅에는 수천개 파일이 필요하다.<br />
DOS 시절 게임 용량은 MB단위였지만, 2000년대 중반 게임들은 로딩 시간이 1분은 필요하게 되었다.<br />
결국 HDD가 데이터 입출력 병목을 만드는 상황이 되었다.<br />
<br />
그리고, HDD는 기계장치 때문에 소형화하면 성능 저하가 크게 일어났고, 저전력 상태로 만드는 데에도 오래 걸려서 저전력 상태를 유지하기 어려웠다.<br />
결국 HDD는 저전력과 고성능 양쪽에 방해됐다.<br />
<br />
플래시메모리는 1980년 도시바에서 마스오카 후지오 박사가 만들었다.<br />
DRAM, SRAM은 전하를 매우 작은 도체로 구성된 공간에 집어넣어 1과 0을 구분했다.<br />
플래시메모리는 더 출입이 어려운 절연 구역에 고전압을 가해 전자를 터널링시켜 가두는 것으로 1과 0을 구분했다.<br />
<br />
당연히, 플래시메모리는 SRAM, DRAM보다 읽기쓰기 속도가 훨씬 느렸다. SRAM, DRAM은 도체랑 바로 붙어있으니까.<br />
<br />
DRAM은 수십나노초면 읽기쓰기가 가능했지만, 플래시메모리는 전압펌프를 가동해서 절연 공간에 전하를 집어넣을 때까지 수십~수천us가 필요했다.<br />
대신, 전자가 갇혀있게 되어 전원을 꺼도 메모리가 유지됐다.<br />
<br />
플래시메모리는 Block 단위로 데이터를 읽고 쓴다. Block 단위로 데이터가 뿅 하고 사라지기 때문에 ‘플래시’메모리라 부른다.<br />
<br />
근데 플래시메모리는 공정상의 한계때문에, 칩 내의 block 중 1% 이상이 결함을 갖고 나온다.<br />
그래서 에러 정정 장치를 붙여서 사용해야 했다.<br />
플래시메모리 제조사는 ‘0번 block은 결함이 없을 것’과 ‘칩 내 불량이 몇개 이하일 것’만 보장해 판매한다.<br />
<br />
플래시메모리는 컨트롤러와 결합하여 운영되며, 컨트롤러 안에 작은 소프트웨어를 탑재해 문제들을 해결한다.<br />
값싼 원가의 대가로 얻은 낮은 질을 소프트웨어로 해결하려는거다.<br />
<br />
NAND, NOR가 있는데 NOR는 Block이 작다. 수 바이트정도 된다.<br />
NAND는 Block이 수kB 수준이다.<br />
그래서 NOR는 각 방에 연결되는 도체를 더 많이 깔아야 하고, 그래서 더 비싸다.<br />
결국 반응속도는 NOR가 더 빠르고, 가격은 NAND가 더 싸다.<br />
쓰기는 NAND가 한번에 뭉텅이로 써서 더 빠르다. 읽기가 NOR가 더 빠른거다.<br />
<br />
후지오 마스오카 박사는 플래시메모리로 마그네틱 기반 저장소를 모두 대체하고 싶어했으나, 도시바는 그 아이디어에 관심이 없었다.<br />
<br />
인텔이 더 먼저 행동했다. 인텔은 CPU 사업을 하고 있었는데, CPU가 구동하기 위해서는 일련의 구동 코드들 및 BIOS를 마더보드에 저장해둘 외부 공간이 필요했다.<br />
그때까지의 컴퓨터들은 이 코드들을 PROM, EPROM, EEPROM에 저장해 왔다.<br />
<br />
하지만 PROM은 물리적으로 퓨즈를 끊어 0과 1을 구분하는 방식이었기 때문에, 실수하면 칩을 못쓰게 될 위험이 존재했다.<br />
EPROM은 데이터를 적기는 쉬운데, 지우려면 자외선을 조사하는 과정이 필요했다.<br />
EEPROM은 사용하기는 쉬웠지만 용량이 너무 작았다.<br />
<br />
플래시메모리는 이런 단점들이 없단느걸 인텔이 알아챘다.<br />
<br />
이 코드들은 컴퓨터 부팅시에만 사용되며, 프로그램 성능에는 영향을 주지 않ㄴ느다. 용량은 수십kB ~ 수십MB만 있으면 된다.<br />
데이터를 바꾸는 일은 BIOS 업데이트를 할 때 정도고, 사용자 환경과 분리되어 운영되기 때문에 데이터 접근 성능에 대한 걱정도 필요없다.<br />
물론 매년 필요한 용량이 증가하긴 했지만 얼마 안됐다. 결국, 그냥 간단하게 사용 가능하고 비휘발성이면 되는거였다.<br />
여기에 NOR 플래시메모리가 쓰이게 된다. 읽는게 빠르니까.<br />
<br />
NAND 플래시의 메모리 특성이 더 안좋았기 때문에, 컨트롤러는 NAND 플래시용 컨트롤러가 더 컸다. 그래도 가격은 NAND가 더 쌌다.<br />
<br />
인텔, 암드는 NOR 플래시메모리에 집중했다. 마더보드 위의 ROM을 대체하기 위함이었으니까.<br />
<br />
도시바는 후발주자가 되어버렸는데, 1991년 낸드플래시 개발을 완료하고 시장 진출을 선언했다.<br />
그리고 1992년, 삼성전자에게 낸드플래시 기술을 라이센싱해주게 된다.<br />
<br />
그 후, 삼성전자는 미래 디지털 제품 기술 확보를 위해 DRAM, NAND, CDMA에 역량을 쏟아붓겠다고 선언한다.<br />
지금 보면 꽤 성공했다.<br />
<br />
Sandisk는 메모리를 직접 제조하지는 않고, 플래시메모리에 들어갈 컨트롤러만 만들었다.<br />
당시 이름은 Sundisk였는데, 나중에 Sandisk로 바꾼거다.<br />
<br />
핸드폰도 발전하기 시작해서, 저장장치가 필요해졌다.<br />
플로피디스크는 성능 향상이 힘들었고, 신뢰하기 힘든 매체가 사용됐다.<br />
CD-ROM은 한번 적은 내용을 고치기 어려웠다.<br />
휴대용 HDD는 크기가 너무 컸고, 충격으로 데이터를 잃어버릴 수도 있었다.<br />
<br />
여기에도 플래시메모리가 쓰이게 된다.<br />
<br />
도시바는 SD(Secure Digital)라는 새로운 규격을 만들었고,<br />
이스라엘의 M-systems는 최초의 휴대용 USB를 만들었다. 자신들의 컨트롤러에 샌디스크의 낸드를 붙였다고 한다.<br />
근데 아까 샌디스크는 컨트롤러만 만들었다며? 뭐지<br />
<br />
당시 USB 용량은 8~16MB라 CD-ROM보다는 용량이 훨씬 작았지만, 휴대성과 안정성은 훨씬 좋았다.<br />
<br />
삼성전자는 DRAM 시장에서 승리한 후, 낸드플래시 비트당 가격이 DRAM보다 높은걸 보고 낸드플래시에 대규모 투자를 하게 된다.<br />
낸드플래시가 DRAM보다 싸지게 됐고, 가격경쟁이 심해지기 시작했다.<br />
<br />
이때쯤, 애플은 iPod보다 발전한 iPod Nano를 만들고 싶어했다.<br />
원래 아이팟에는 소형 HDD가 있었는데, 더 소형화하기 위해 플래시메모리를 쓰게 됐다.<br />
당시 NOR 대비 NAND 플래시의 칩당 밀도가 10배정도 높아서, 애플은 NAND 플래시를 쓰게 됐다. 이때, 삼성전자의 NAND플래시를 쓰게 된다.<br />
<br />
이 아이팟 나노가 엄청난 히트를 치게 되어, CD나 HDD 기반 음악감상 장치들이 도태되고 플래시메모리 기반 제품들이 많이 나오게 된다.<br />
결국 플래시메모리가 많이 필요해졌고, 삼성전자는 엄청난 이득을 보게 된다.<br />
<br />
다른 낸드 제조사들도 이득을 봤지만, 삼성전자에게 특히 유리했던 점은 삼성전자는 도시바와 달리 DRAM 사업부, 파운드리사업부도 있었다는 점이다.<br />
아이팟 나노는 모바일 SD램과 일종의 CPU인 미디어 프로세서도 필요했는데, 삼성전자는 이걸 다 만들어줄 수 있었다.<br />
<br />
그래서 애플에게 미디어 프로세서를 공급하던 팹리스 업체인 PortalPlayer는 2006년 애플과의 계약이 종료됐음을 발표하고, 이후 엔비디아에 인수된다.<br />
그 계약들이 다 삼성전자한테 넘어간거다.<br />
<br />
물론 모든 낸드 제조사들이 이득을 본건 아니었다. 일본의 르네사스 반도체는 2010년 12월, 더이상 낸드 개발을 하지 않겠다고 선언한다.<br />
<br />
2005년, 애플 아이팟 나노 덕분에 돈이 많아진 삼성전자는 갑자기 새로운 사업을 발표한다.<br />
1.8인치, 2.5인치 SSD시장에 진출하겠다는거다.<br />
<br />
SSD 1TB, HDD 10TB여도 SSD 1TB를 고를 수 있으니까. 10TB까지 필요 없잖아?<br />
<br />
그리고 SSD는 내충격성, 성능이 높으니 충격 방지 설계 비용, CPU에 소모될 예산을 아낄 수 있으니 전체 비용이 줄고 경량화가 가능하다.<br />
<br />
그리고 HDD컨트롤러보다 SSD컨트롤러가 더 만들기 쉬웠다. 기계적인거 신경 안써도 되니까.<br />
<br />
2006년: 삼성전자가 최초의 양산형 SSD를 699달러에 발표한다. 32GB짜리였다.<br />
<br />
이후 비슷한 SSD들이 컨트롤러 업체들에서 등장한다. 플렉스터, 퓨전IO, OCZ, Silicon Motion 등 업체들이었다.<br />
이 팹리스 업체들은 낸드를 사와서 자사 컨트롤러에 붙여 팔기 시작했다.<br />
<br />
UBER: 수정 불가능한 에러가 발생할 확률. Uncorrectable Bit Error Rate<br />
<br />
삼성전자는 DRAM때는 원가경쟁으로 경쟁업체들을 말려죽였고, 낸드 시장에서는 낸드와 다른 하드웨어들을 결합한 솔루션(노트북, 아이팟나노 등)들을 제공했다. NOR 대신 NAND쪽을 선택한 것도 옳은 선택이었다.<br />
(107페이지 삼성전자 연표)<br />
<br />
ISA: Instruction Set Architecture. 인텔, AMD CPU는 인텔의 ISA인 x86, x86-64를 쓴다.<br />
ARM CPU는 ARM V8을 쓴다.<br />
<br />
exe: 실행 파일. 사용자가 직접 클릭해서 실행할 수 있는 파일<br />
dll: 동적 라이브러리. 다른 실행파일이 불러와서 사용할 수 있는 형태의 파일.<br />
<br />
Compiler별로 프로그램 성능이 많이 달라질 수 있다. How are you?를 ‘요즘 어떻게 지내니?’, ‘요즘 어때?’ 등으로 번역 가능한 것처럼<br />
<br />
Compiler, 기계어는 인간이 다루기 어렵다.<br />
<br />
1977년 발사된 보이저1,2호의 메모리는 68kB였다. 보이저의 제어 프로그램은 기계어와 포트란으로 만들어졌다. 이 정도는 인간이 기계어로 만들 수 있다.<br />
<br />
근데, 예를 들어 윈도우 7은 4기가짜리다. 이런건 인간이 기계어로 못만든다.<br />
<br />
옛날 컴퓨터에는 확장 슬롯 자체가 없거나, 공인된 하드웨어만 붙일 수 있었다.<br />
<br />
1981년 IBM이 XT라는 컴퓨터를 만들었는데, 서드파티에게 컴퓨터를 오픈하고, 보조기억장치로 HDD와 플로피디스크를 갖추고, 확장 가능한 램 슬롯을 가진 구조였다.<br />
CPU는 인텔 8088, OS는 MS-DOS였다.<br />
<br />
당시에는 컴퓨터 관련 표준이 거의 없어서, 당시 컴퓨터들은 CPU가 동일한 ISA를 사용하더라도, 아니면 아예 같은 CPU를 사용하더라도 프로그램이 제대로 안돌아가는 경우가 많았다.<br />
요즘은 어느 회사 RAM을 쓰든, 어느 회사 GPU를 쓰든 잘 작동하잖아? 그때는 공식적으로 인정된 부품만 써야 했다.<br />
<br />
그래서 IBM PC가 혁신이었다. 맘대로 하드웨어 갈아끼울 수 있다니!<br />
<br />
당시 인텔8088은 가격이 저렴하고 성능이 뛰어났다. 그리고 인텔 x86-16은 CISC 명령어 체계를 사용하고 있었는데, x86-16에는 범용 레지스터(CPU 내부 연산 처리를 위한 초고속 저장공간)가 훨씬 많아서, 코드를 잘 짜면 경쟁자들을 압도할 수 있었다.<br />
<br />
그리고 8088은 내부로는 16비트를 사용해서 성능을 끌어올렸지만, 외부로는 8비트 버스를 갖고 있었다.<br />
당시 시장에 나온 하드웨어들은 다 8Bit였기 때문에 이게 나았다.<br />
<br />
그 후 모든 회사들이 달려들어 IBM PC를 리버스엔지니어링 했다. 모두가 IBM PC에 맞는 규격의 하드웨어, 소프트웨어를 만들게 되었다.<br />
<br />
그 전에는 다 규격이 달라서 거래처가 바뀌면 싹 다 다시 해야 했다.<br />
하지만 이제는 IBM PC 규격이 표준이 되어 이거대로 만들면 되는 상황이 됐다.<br />
<br />
그래서 IBM은 이득을 봤나? 그건 아니다. IBM도 경쟁자 중 하나가 되어버리고 말았다. 그래서 별로 이득 못봤다.<br />
<br />
그래도 PC 사업은 IBM의 사업들 중 하나였기 때문에 큰 타격은 없었다. IBM은 지금도 메인프레임 시장의 절대자다.<br />
<br />
이 시점에, 인텔은 두가지 결정을 내린다.<br />
1. 일본과의 DRAM 경쟁을 포기하고 CPU에 집중한다.<br />
2. 프로세서 생산을 타사에 맡기지 않는다.<br />
<br />
인텔을 왕좌에 올린 8088 프로세서를 위탁 생산하던 회사는 AMD, NEC, 후지츠 등 10개 가까이 되었다.<br />
이렇게 아웃소싱을 돌려서 웨이퍼 공장을 작게 유지하고 있었지만, Value chain의 상당 부분을 다른 회사들과 나눠 가져야 했고, 기술이 새어나갈 위험도 있었다.<br />
<br />
인텔은 자기 제품을 타사에 맡기지 않게 되며, 전세계 PC CPU의 설계부터 제조까지 모든 Value Chain을 장악하게 됐다.<br />
<br />
인텔이 자체 생산으로 물량을 돌릴 때, AMD는 인텔의 x86 ISA만 라이센싱하고 설계는 자체적으로 하기로 했다.<br />
인텔이 CPU 시장을 먹어버리긴 했지만, CPU는 수명이 길기 때문에 인텔은 과거 제품보다 더 좋은 제품들을 계속 만들어내야 했다.<br />
게다가 AMD도 쫓아오고 있었다.<br />
<br />
그래서, 독점시장이어도 인텔은 가만히 있을 수가 없었다.<br />
<br />
데너드 스케일링: 미세공정 발전으로 면적당 트랜지스터가 늘어나도 전력 소모는 늘어나지 않는다<br />
인텔은 전력 소비량을 유지하며 더 많은 부품을 CPU에 빽빽히 꽂아넣어 성능을 늘릴 수 있었다.<br />
또, 약간 밀도를 낮춰 동작 마진을 주는 것으로, 더 높은 clock으로 동작할 수 있게 했다.<br />
<br />
인텔은 과거 CPU에서 동작하는 프로그램들은 모두 상위 CPU에서도 동작하게 만들었다.<br />
뭐 ISA를 갈아엎는다거나 이런 행동을 하지 않은거다.<br />
<br />
컴퓨터가 발전하고 메모리 용량이 커지자, 인텔은 x86-16에서 x86-32로 넘어갔다. x86-16은 64kB 이상 메모리를 인식할 수 없기 때문이다.<br />
인텔 80386에서 이 변화가 발생했는데, 옛날 프로그램들 잘 돌아가도록 ‘Virtual 8086 mode’를 만들어놨다.<br />
지금도 가상환경에서는 8086 명령어 다 돌아간다.<br />
8086 프로세서는 트랜지스터 3만개인데, 요즘 프로세서들은 1억개 이상이다. 사실 아예 프로세서를 집어넣을 수도 있는거다.<br />
<br />
이런 호환성 유지는 쉬운 일이 아니다. 요즘 잘 안쓰는 명령어도 들고 가야 하니 웨이퍼 면적, 전력 낭비가 어느 정도씩 발생하게 된다.<br />
인텔은 이걸 감내하면서도 성능을 향상시킬 방법을 찾아나갔다.<br />
<br />
성능을 높이는 한가지 방법은 clock을 높이는 것이었다.<br />
최신 제조장비를 도입해서 미세공정 품질을 높이고, 이를 통해 cell의 크기를 줄이고 누설전류와 발열을 억제해 CPU의 최대 스위칭속도를 높이는거다.<br />
이걸로 clock이 2배 높아지면 CPU 성능도 2배가 된다.<br />
<br />
하지만 switching 속도가 너무 빨라지면 원래 같이 동작하는걸 전제로 만들었던 회로가 따로 동작할 수도 있다.<br />
(그림)<br />
<br />
1GHz면 30cm 이동하니까, 길이가 30cm 넘어가면 다른 clock이 걸리게 된다. 4GHz면 7.5cm<br />
그래서 한 덩어리였던 하드웨어 블록을 여러 덩어리로 쪼개야 한다. 이게 파이프라인이다.<br />
<br />
다른 방법은 아키텍처를 넓히는 것이다. 인텔 Sandy Bridge, Haswell, Skylake 등이 이런 아키텍처의 코드명이다.<br />
한개 CPU core에서 병렬로 동시에 처리될 수 있는 작업들이 생기는데, 이런걸 ‘ILP(Instruction Level Parallelism)’이라 부른다.<br />
이 ILP들을 찾아내 성능을 높이는 CPU를 Superscalar Processor라 한다.<br />
물론, 이 ILP 찾는건 아주 빠르게 이뤄져야 하기 때문에 만들기 Superscalar Processor를 만드는게 어렵다.<br />
하지만 이걸 해내면, clock도 안바꿨는데 CPU가 빨라진다!<br />
<br />
마지막 방식은 새로운 명령어를 ISA에 추가하는거다. 특정 상황에서 아주 빠르게 동작할 수 있는 신규 명령어,<br />
그걸 위한 하드웨어들을 추가하는거다.<br />
예시로는 인텔 펜티엄의 MMX, 펜티엄3의 SSE, 코어 시리즈의 AVX등의 SIMD(Single Instruction Multiple Data) 명령어들이 있다.<br />
한개 Instruction으로 여러개 숫자열 상태가 바뀐다.<br />
<br />
근데 이 방식은 다른 두 방식과 다르게, 프로그래머가 이 새로운 명령어를 써줘야 동작이 빨라진다.<br />
그리고, 과거 CPU들은 이 새로운 명령어를 이해 못하기에 프로그램을 돌릴 수 없게 된다.<br />
ex) 386은 MMX가 적용된 프로그램을 못돌린다.<br />
<br />
새로운 명령어가 추가되면 Compiler를 새로 만들어야 하는데, 인텔이 스스로 Compiler(ICC)를 만들어 팔았다.<br />
그래서 프로그램 개발이 그렇게 어렵지 않았고, 어차피 이런거까지 써야 하는 하이엔드 성능이 필요한 프로그램이면 옛날 CPU에서 안돌아가는게 문제가 되지 않았다.<br />
<br />
그래픽 작업이 병렬인 이유: 모니터에 표시되는 픽셀들은 서로 상호작용하지 않기 때문에 병렬이다.<br />
<br />
인텔은 램버스와 협력해 RD램을 만들어 다시 한번 메모리 시장에 들어가 PC 플랫폼에 대한 영향력을 늘리려 했지만, 메모리 기업들과의 원가 싸움에서 또 털리고 만다.<br />
<br />
20세기 말, 컴퓨터 성능과 용량이 기하급수적으로 늘어나고 있었다.<br />
32비트 기반이었던 x86은 한번에 접근 가능한 메모리 영역이 4GB였는데, 메모리 용량이 점점 커져서 곧 메모리에 한번에 접근하지 못하게 될 위기였다.<br />
접근 자체는 가능한데, 여러 단계를 거쳐야 하니 효율성이 떨어지는 상황이었다.<br />
<br />
인텔은 CPU를 64비트로 바꾸고 최대 메모리 주소를 늘려야 하는 상황이었는데, 20년간 유지해온 하위호환 정책에 대해 다시 생각해보게 됐다.<br /></p>

<p>신형 칩들 clock은 계속 올라서 2000년에는 1GHz를 넘었고, 실리콘 웨이퍼가 버틸 수 있는 최대 clock인 4~5GHz 근처로 빠르게 다가가고 있었다.</p>

<p>그리고, 만들어진지 20년이 넘은 인텔의 x86은 각 명령어마다 길이가 달랐기 때문에(CISC),
그 후 생긴 모든 명령어의 길이가 같은(RISC) ARM 프로세서보다 비순차 수행에 적합하지 못했다.</p>

<p>비순차수행에서는 명령어들의 순서를 바꾸는 과정이 필요한데, 명령어들의 길이가 같으면 쉽지만 다르면 어렵다.</p>

<p>그리고, CPU가 추출해낼 수 있는 동시 수행 가능성도 한계였다.</p>

<p>인텔은 여기서, x86을 포기하고 앞으로 나아가기로 한다. 이때 HP와 협력한다.</p>

<p>HP는 1980년부터 RISC도 CISC도 아닌 대안 아키텍처를 고민하고 있었다.</p>

<p>2001년, 인텔은 HP와 협력하여 새로운 CPU 아키텍처인 Itanium을 발표했다.
기존 CPU들은 비순차 수행 방식으로 성능을 끌어올렸는데, 인텔의 새로운 CPU는 그런 복잡한 비순차 수행 엔진(명령어 배치 장치)을 만들 웨이퍼 면적을 추가 연산장치에 투자하는 방향으로 갔다.</p>

:ET