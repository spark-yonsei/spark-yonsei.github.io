I"9(<p>특정 연산에 특화된 하드웨어를 가속기(Accelerator) 또는 ASIC(Application Specific IC)라 부른다.<br />
인공지능 가속기 팹리스 업체는 인공지능 연산에 특화된 가속기를 설계하는 업체다.<br />
<br />
<br />
대표적인 인공지능 가속기 업체로는 엔비디아가 있다.<br />
엔비디아는 다양한 인공지능 가속기들을 출시했고, 수많은 기업들이 엔비디아의 제품을 사용하고 있다.<br />
<br />
엔비디아는 GPU 프로그래밍을 위한 프로그래밍 언어 CUDA도 출시한 바 있다.<br />
CUDA를 통해 개발자들은 GPU를 그래픽 연산 용도가 아닌 인공지능 연산 용도로 사용할 수 있게 되었다.<br />
그래서 CUDA를 통해 다양한 인공지능 연산 프로그램과 인공지능 모델이 개발됐다.<br />
<br />
그런데, CUDA로 만들어진 프로그램은 엔비디아 제품에서만 실행된다.<br />
결국 CUDA로 만들어진 인공지능 모델을 사용하려면 엔비디아 제품을 사야 하고,<br />
엔비디아 제품에서 인공지능 연산 프로그램 및 모델을 개발하려면 CUDA를 써야 한다.<br />
이렇게 해서 엔비디아는 인공지능 가속기 시장을 강력하게 지배하고 있다.<br />
<br />
<br />
엔비디아 하드웨어와 CUDA를 통해 인공지능이 크게 발전했고, 막대한 연산을 필요로 하는 거대한 모델들이 개발됐다.<br />
이 거대한 인공지능 모델들은 성능이 좋긴 한데, 연산 과정에서 엄청난 전력을 소비한다.<br />
그래서 더 효율적인 연산을 하는 하드웨어가 필요하게 됐다.<br />
<br />
<br />
전력 소모를 감당하기 어려워진 거대 클라우드 회사들은 그들 각자의 수요에 맞는 칩을 설계하기 시작했다.<br />
예를 들어, 구글은 구글의 Tensorflow 라이브러리에 최적화된 TPU(Tensor Processing Unit)를 설계해 자사 데이터센터에 쓰고 있다.<br />
<br />
그 외에도 주로 실행하는 연산, 사용하는 인공지능 모델이 있는 기업들은 거기에 특화된 인공지능 가속기를 원하고 있다.<br />
그래서, 이런 기업들을 위해 특화된 인공지능 가속기를 설계해주는 팹리스 회사들이 생기기 시작했다.<br />
<br />
<br />
인공지능 가속기를 설계할 때에는 latency, throughput, efficiency를 고려해야 한다.<br />
여기서 latency와 throughput은 성능의 지표고, efficiency는 전력 효율의 지표다.<br />
일반적으로, 가속기의 성능을 개선하면 전력 효율이 악화되고, 전력 효율을 개선하면 성능이 악화된다.<br />
<br />
latency:<br />
연산에 걸리는 시간<br />
latency가 작을수록 빠르게 연산을 할 수 있다.<br />
<br />
throughput:<br />
단위시간당 시행하는 연산의 갯수<br />
throughput이 클수록 많은 수의 연산을 할 수 있다.<br />
<br />
<br />
가속기 내에서 연산 자원을 직렬로 연결하면 latency가 작고, throughput도 작은 가속기가 된다.<br />
즉 연산은 빠르지만, 동시에 처리할 수 있는 데이터의 수는 작은 가속기가 된다.<br />
<br />
연산 자원을 병렬로 연결하면 latency가 크지만, throughput이 큰 가속기가 된다.<br />
즉 연산은 느리지만, 동시에 처리할 수 있는 데이터의 수가 큰 가속기가 된다.<br />
<br />
<br />
그래서, 인공지능 가속기를 설계하는 팹리스 업체는 고객이 원하는 연산과 모델에 맞게 칩 내에 연산 자원을 배치하고,<br />
그 칩의 latency, throughput, efficiency를 모두 최적화한 제품을 제공하는 것이 목표다.<br />
<br />
예를 들어 한국의 리벨리온은 극히 빠른 AI 기반 금융거래를 위해 latency만을 극도로 낮춘 칩을 개발한 바 있다.<br />
<br />
<br />
인공지능 가속기 팹리스 업체가 해야 하는 일은 이뿐만이 아니다.<br />
현재 인공지능 가속기 시장은 엔비디아가 지배하고 있기 때문에,<br />
‘당신들이 주로 하는 연산에서는 엔비디아 제품보다 우리 제품이 더 좋다’고 설득해서 고객을 뺏어와야 한다.<br />
<br />
또한, 수많은 인공지능 개발자들이 제품을 사용하게 만들려면 CUDA보다 사용하기 편한 프로그래밍 환경을 제공해야 한다.<br />
그래서, 인공지능 가속기 팹리스 업체들은 소프트웨어 개발 및 생태계 운영을 위해 노력하고 있다.<br />
<br />
인공지능 가속기 칩을 개발할 때에도, 이 업체들은 CUDA로 개발된 인공지능 모델을 자사 소프트웨어로 이식해와야 한다.<br />
<br />
인공지능 가속기 칩을 설계한 후에는 안정성 평가가 매우 중요하다.<br />
현재 인공지능 가속기는 대부분 데이터센터에 쓰이고 있는데,<br />
데이터센터는 오작동할 경우 고객들에게 막대한 피해보상을 해야 하기 때문이다.<br />
<br />
그래도, 인공지능 가속기를 설계할 때 편한 점도 있다.<br />
목표한 연산이 잘 실행되는지만 확인하면 되기 때문에, 칩 테스트가 비교적 쉽다.<br />
<br />
<br />
현재, 국내외 수많은 스타트업들이 인공지능 가속기 설계를 하고 있다.<br />
한국 인공지능 반도체 시장에서는 사피온, 퓨리오사, 리벨리온 3개 기업이 유명하다.<br />
<br />
<br />
사피온:<br />
SKT, SK하이닉스, SK스퀘어 3개 회사에서 공동으로 출자해 설립된 회사다.<br />
<br />
SK 그룹은 반도체 공정 전반에 걸쳐 회사를 갖고 있기에, 팹리스 기업인 사피온은 SK 계열사들의 지원을 받을 수 있는 위치에 있다.<br />
SK 그룹의 반도체 공정 관련 회사: SK하이닉스(소자), SK머티리얼즈/SK가스(특수가스), SK실트론(웨이퍼, 단결정실리콘)<br />
<br />
또한, 신기술 시장일수록 제품의 성능을 증명하기 위해 시장에 적용된 사례가 필요한데, 최대주주 SKT가 사용처를 제공해줄 수 있다.<br />
사피온은 인공지능 가속기 X220을 개발해 NHN클라우드, SKT, MBC에 공급한 바 있다.<br />
<br />
<br />
퓨리오사AI:<br />
퓨리오사AI는 컴퓨터비전 관련 연산에 특화된 인공지능 가속기 Warboy를 출시했다.<br />
<br />
카카오엔터프라이즈는 자사의 클라우드 서비스 카카오 클라우드에 Warboy를 사용한다.<br />
대표적으로, ‘말해보카’ 어플의 OCR(Optical Character Recognition, 광학 문자 인식) 기능 연산이 Warboy에서 실행된다고 한다.<br />
<br />
<br />
리벨리온:
리벨리온은 빠른 연산에 특화된 인공지능 가속기 Ion을 출시했다.<br />
<br />
Ion은 리벨리온의 제품 LightTrader에 들어간다.<br />
LightTrader는 인공지능 기반 HFT(High Frequency Trading)를 위한 PCIe card다.<br />
<br />
리벨리온의 다른 인공지능 가속기 ATOM은 컴퓨터비전, 자연어처리 연산에 특화된 구조를 갖고 있다.<br />
KT클라우드는 리벨리온의 데이터센터용 인공지능 가속기 ATOM을 데이터센터 구축에 사용했다.<br />
<br />
<br />
외국에도 수많은 AI가속기 스타트업들이 있다.<br />
<br />
<br />
Tenstorrent:<br />
Jim Keller(짐 켈러)가 CEO로 있는 인공지능 가속기 팹리스 기업이다.<br /></p>

<p><br />
<br />
PFN(Preferred Networks):<br />
일본의 인공지능 가속기 팹리스 기업이다.<br />
PFN은 인공지능 가속기를 설계하기도 하고, 다양한 인공지능 솔루션들을 기업에 제공하기도 한다.<br />
<br />
PFN은 2015년부터 화낙(FANUC, 로봇 팔 회사)과 협업하고 있고,<br />
화낙에서는 2017년부터 머신러닝 및 딥러닝 기술이 적용된 제품들이 나오고 있다.<br />
<br />
이미지, 음성인식 인공지능에 집중했던 구글이나 메타와 달리,<br />
PFN은 처음부터 공장 장비 및 운영에 인공지능을 도입하는 것을 목표로 했다.<br />
그래서 구글, 메타 등 거대 기업들과 경쟁할 일이 없었다.<br />
<br />
현재는 의료영상처리, 자율주행 등 다양한 분야에 AI솔루션을 제공하고 있으며,<br />
한국에서는 삼성전자 파운드리 2나노 공정으로 차세대 인공지능 가속기를 생산하기로 해 화제가 되기도 했다.<br />
<br />
<br /></p>

<p>메모리 업체 입장:
RDIMM(고성능 DRAM 모듈)의 수요가 증가했고, 서버용 SSD 수요가 늘어나 낸드플래시 매출이 올라갔다.<br />
메모리 회사들도 돈벌고, 가상화 호스팅 업체들도 돈 많이 벌었다.<br />
<br />
휴대용 디바이스 수요 증가-&gt; 그거에 맞는 칩 설계하는 팹리스 성장 -&gt; 파운드리 매출도 성장<br />
<br />
전통적인 CPU 성능 증가에 한계, AI 등 응용프로그램 등장 -&gt; GPU, FPGA 등 특정 연산에 강점을 보이는 칩들이 연산용 반도체의 주도권을 갖게 됐다.<br />
<br />
기존 회사들은 CPU에 최적화된 프로그램을 버리고, 전용 가속기에 맞는 프로그램을 설계하게 됐다.<br />
<br />
메모리 구조가 바뀔 필요는 없었다. 메모리 회사들은 그냥 팔면 됐고,<br />
대규모 병렬 처리가 많이 필요해지면서 HBM같은 고부가가치 고성능 메모리에 대한 수요가 생겼다.<br />
<br />
전통적인 로직 반도체 회사들은 모바일 플랫폼 발전+GPU 수요 상승에 편승 못하고 매출에 타격을 입었지만,<br />
AWS 등 서버 서비스가 확장되어 서버용 CPU를 팔며 이득을 보긴 했다.<br /></p>

<p>아니 근데 스타트업들이 많은데, 더 좋은 제품 만드는게 가능하냐?<br />
딱 한가지 기능만을 위해 설계하는거라, 인재들이 모인다면 가능하다. 원래 엘리트 비즈니스다.<br /></p>

<p>원래 시스템반도체 업계는 특화기업들이 살아남는거다.<br /></p>

<p>파운드리 업체 입장:
삼성전자 파운드리가 분리 안되어있는게 꼭 나쁜건 아닐 수 있다.
삼성전자 HBM의 원활한 공급을 위해 삼성전자 파운드리를 선택할 수도 있다.</p>
:ET